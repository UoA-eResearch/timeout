pandas
tqdm
yt-dlp[default,curl-cffi]
accelerate
torch
json5
ipython-autotime
qwen-omni-utils
torchvision
transformers<5
https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.7.16/flash_attn-2.8.3+cu128torch2.10-cp311-cp311-linux_x86_64.whl
